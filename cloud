#!/usr/bin/env bash
#
# Cloud installation management tool.
# Assumes its location is the top directory of KCIDB source tree.
# Deploying creates or updates an installation, withdrawing removes it.
#
# Conventions:
#   - *_deploy functions create or update an installation;
#   - *_withdraw functions delete installation if it exists;
#   - no output should be produced unless something fails;
#   - no error/message output on stdout, only stderr.

set -euCo pipefail
shopt -s extglob

PATH="$(dirname "$(realpath "$0")")/kcidb/cloud:$PATH"

. psql.sh
. pubsub.sh
. firestore.sh
. password.sh
. secret.sh
. aterr.sh
. misc.sh

# Enable Google Cloud services using their short names
# Args: project [name...]
function services_enable() {
    declare -r project="$1"; shift
    declare -a names=("$@")
    for ((i = 0; i < ${#names[@]}; i++)); do
        names[$i]="${names[$i]}.googleapis.com"
    done
    mute gcloud services enable --quiet --project="$project" "${names[@]}"
}

# Deploy to BigQuery
# Do not initialize datasets that are prepended with the hash sign ('#').
# Args: project dataset...
function bigquery_deploy() {
    declare -r project="$1"; shift
    declare dataset
    declare init
    for dataset in "$@"; do
        # Handle possible leading hash sign
        if [[ $dataset == \#* ]]; then
            dataset="${dataset:1}"
            init=false
        else
            init=true
        fi
        mute bq mk --project_id="$project" --force "$dataset"
        if "$init"; then
            kcidb-db-init -lDEBUG -d "bigquery:${project}.${dataset}" \
                          --ignore-initialized
        fi
    done
}

# Withdraw from BigQuery
# Cleanup all datasets, even those prepended with the hash sign ('#').
# Args: project dataset...
function bigquery_withdraw() {
    declare -r project="$1"; shift
    declare dataset
    for dataset in "$@"; do
        # Ignore possible leading hash sign
        dataset="${dataset###}"
        kcidb-db-cleanup -lDEBUG -d "bigquery:${project}.${dataset}" \
                         --ignore-not-initialized \
                         --ignore-not-found
        mute bq rm --project_id="$project" --force "$dataset"
    done
}

# Check if the App Engine app exists.
# Args: project
# Output: "true" if the app exists, "false" otherwise.
function app_exists() {
    declare -r project="$1"; shift
    declare output
    if output=$(
            gcloud app describe --quiet --project="$project" 2>&1
       ); then
        echo "true"
    elif [[ $output == *\ does\ not\ contain\ * ]]; then
        echo "false"
    else
        echo "$output" >&2
        false
    fi
}

# Create the App Engine app, if it doesn't exist.
# Args: project
function app_deploy() {
    declare -r project="$1"; shift
    exists=$(app_exists "$project")
    if "$exists"; then
        return
    fi
    mute gcloud app create --quiet --project="$project" --region=us-central
}

# The name of the shared SMTP password secret
declare -r SMTP_PASSWORD_SECRET="kcidb_smtp_password"

# Deploy secrets
# Args: project
#       psql_pgpass_secret
#       psql_submitter_username
function secrets_deploy() {
    declare -r project="$1"; shift
    declare -r psql_pgpass_secret="$1"; shift
    declare -r psql_submitter_username="$1"; shift
    declare exists

    # Make sure the shared SMTP password secret is deployed
    password_deploy_secret smtp
    # Give Cloud Functions access to the shared SMTP password secret
    mute gcloud secrets add-iam-policy-binding \
        --quiet --project="$project" "$SMTP_PASSWORD_SECRET" \
        --role roles/secretmanager.secretAccessor \
        --member "serviceAccount:$project@appspot.gserviceaccount.com"

    # Make sure all PostgreSQL's password secrets are deployed
    password_deploy_secret psql_superuser psql_submitter psql_viewer
    # DO NOT give Cloud Functions access to *any* PostgreSQL password secrets

    # Make sure PostgreSQL's .pgpass secret is deployed
    password_deploy_pgpass_secret "$project" "$psql_pgpass_secret" \
        psql_submitter "$psql_submitter_username"

    # Give Cloud Functions access to the .pgpass secret
    mute gcloud secrets add-iam-policy-binding \
        --quiet --project="$project" "$psql_pgpass_secret" \
        --role roles/secretmanager.secretAccessor \
        --member "serviceAccount:$project@appspot.gserviceaccount.com"
}

# Withdraw secrets
# Args: project
#       psql_pgpass_secret
function secrets_withdraw() {
    declare -r project="$1"; shift
    declare -r psql_pgpass_secret="$1"; shift
    password_withdraw_secret psql_submitter
    secret_withdraw "$project" "$psql_pgpass_secret"
    # NOTE: Not withdrawing the shared secrets
}

# Deploy a Google Cloud Storage Bucket
# Args: project bucket
function storage_deploy() {
    declare -r project="$1"; shift
    declare -r bucket="$1"; shift
    # Check if the bucket exists
    if ! TMPDIR="$TMPDIR_ORIG" gsutil ls "gs://$bucket" &>/dev/null; then
        # Create the bucket if it doesn't exist
        TMPDIR="$TMPDIR_ORIG" gsutil -q mb -p "$project" -c STANDARD \
            -l "us-central1" -b on "gs://$bucket"
    fi
    TMPDIR="$TMPDIR_ORIG" gsutil -q iam ch allUsers:objectViewer "gs://$bucket/"
}

# Remove a Google Cloud Storage Bucket and its contents
# Args: bucket
function storage_withdraw() {
    declare -r bucket="$1"; shift
    # Check if the bucket exists
    if TMPDIR="$TMPDIR_ORIG" gsutil ls "gs://$bucket" &>/dev/null; then
        # Remove the bucket and its contents if it exists
        TMPDIR="$TMPDIR_ORIG" gsutil -q -m rm -r "gs://$bucket"
    fi
}

# The region used to host our Cloud Functions
declare -r CLOUD_FUNCTION_REGION="us-central1"

# Deploy a Cloud Function
# Args: sections source project prefix name [param_arg...]
function cloud_function_deploy() {
    declare -r sections="$1"; shift
    declare -r source="$1"; shift
    declare -r project="$1"; shift
    declare -r prefix="$1"; shift
    declare -r name="$1"; shift
    sections_run_explicit "$sections" \
        "cloud_functions.$name" deploy \
        mute gcloud functions deploy --quiet --project="$project" \
                                     --region="$CLOUD_FUNCTION_REGION" \
                                     --docker-registry=artifact-registry \
                                     --runtime python39 \
                                     --source "$source" "${prefix}${name}" \
                                     --entry-point "kcidb_${name}" \
                                     "$@"
}

# Delete a Cloud Function (without complaining it doesn't exist).
# Accepts the arguments of "gcloud functions delete".
function cloud_function_delete()
{
    declare output
    if ! output=$(gcloud functions delete "$@" 2>&1) &&
       [[ $output != *\ status=\[404\]* ]]; then
        echo "$output" >&2
        false
    fi
}

# Delete a Cloud Function if it exists
# Args: sections project prefix name
function cloud_function_withdraw() {
    declare -r sections="$1"; shift
    declare -r project="$1"; shift
    declare -r prefix="$1"; shift
    declare -r name="$1"; shift
    sections_run_explicit "$sections" \
        "cloud_functions.$name" withdraw \
        cloud_function_delete --quiet --project="$project" "${prefix}${name}"
}

# Output deployment environment for Cloud Functions
# Args: --format=yaml|sh
#       --project=ID
#       --log-level=NAME
#       --cache-bucket-name=NAME
#       --optimize=PYTHONOPTIMIZE
#       --heavy-asserts=true|false
#       --new-topic=NAME --new-load-subscription=NAME
#       --updated-publish=true|false
#       --updated-topic=NAME
#       --updated_urls_topic=NAME
#       --cache-bucket-name=NAME
#       --cache-redirector-url=URL
#       --spool-collection-path=PATH
#       --extra-cc=ADDRS
#       --smtp-to-addrs=ADDRS --smtp-password-secret=NAME
#       --smtp-topic=NAME --smtp-subscription=NAME
#       --pgpass-secret=NAME
#       --database=SPEC
#       --clean-test-databases=SPEC_LIST
#       --empty-test-databases=SPEC_LIST
function cloud_functions_env() {
    declare params
    params="$(getopt_vars format \
                          project \
                          log_level \
                          optimize \
                          heavy_asserts \
                          new_topic new_load_subscription \
                          updated_publish updated_topic \
                          updated_urls_topic \
                          spool_collection_path \
                          extra_cc \
                          smtp_to_addrs smtp_password_secret \
                          smtp_topic smtp_subscription \
                          pgpass_secret \
                          cache_bucket_name \
                          cache_redirector_url \
                          database \
                          clean_test_databases \
                          empty_test_databases \
                          -- "$@")"
    eval "$params"
    declare -A env=(
        [GCP_PROJECT]="$project"
        [KCIDB_LOG_LEVEL]="$log_level"
        [PYTHONOPTIMIZE]="${optimize}"
        [KCIDB_LOAD_QUEUE_TOPIC]="$new_topic"
        [KCIDB_LOAD_QUEUE_SUBSCRIPTION]="$new_load_subscription"
        [KCIDB_LOAD_QUEUE_MSG_MAX]="256"
        [KCIDB_LOAD_QUEUE_OBJ_MAX]="8192"
        [KCIDB_LOAD_QUEUE_TIMEOUT_SEC]="30"
        [KCIDB_PGPASS_SECRET]="$pgpass_secret"
        [KCIDB_DATABASE]="$database"
        [KCIDB_DATABASE_LOAD_PERIOD_SEC]="180"
        [KCIDB_CLEAN_TEST_DATABASES]="$clean_test_databases"
        [KCIDB_EMPTY_TEST_DATABASES]="$empty_test_databases"
        [KCIDB_UPDATED_QUEUE_TOPIC]="$updated_topic"
        [KCIDB_UPDATED_URLS_TOPIC]="$updated_urls_topic"
        [KCIDB_SELECTED_SUBSCRIPTIONS]=""
        [KCIDB_SPOOL_COLLECTION_PATH]="$spool_collection_path"
        [KCIDB_SMTP_HOST]="smtp.gmail.com"
        [KCIDB_SMTP_PORT]="587"
        [KCIDB_SMTP_USER]="bot@kernelci.org"
        [KCIDB_SMTP_PASSWORD_SECRET]="$smtp_password_secret"
        [KCIDB_SMTP_FROM_ADDR]="bot@kernelci.org"
        [KCIDB_CACHE_BUCKET_NAME]="$cache_bucket_name"
        [KCIDB_CACHE_REDIRECTOR_URL]="$cache_redirector_url"
    )
    if [ -n "$extra_cc" ]; then
        env[KCIDB_EXTRA_CC]="$extra_cc"
    fi
    if [ -n "$smtp_to_addrs" ]; then
        env[KCIDB_SMTP_TO_ADDRS]="$smtp_to_addrs"
    fi
    if [ -n "$smtp_topic" ]; then
        env[KCIDB_SMTP_TOPIC]="$smtp_topic"
        env[KCIDB_SMTP_SUBSCRIPTION]="$smtp_subscription"
    fi
    if "$heavy_asserts"; then
        env[KCIDB_IO_HEAVY_ASSERTS]="1"
        env[KCIDB_HEAVY_ASSERTS]="1"
    fi
    if "$updated_publish"; then
        env[KCIDB_UPDATED_PUBLISH]="1"
    fi
    if [ "$format" == "yaml" ]; then
        # Silly Python and its significant whitespace
        sed -E 's/^[[:blank:]]+//' <<<'
            import sys, yaml
            args = sys.argv[1::]
            middle = len(args) >> 1
            yaml.dump(dict(zip(args[:middle], args[middle:])),
                      stream=sys.stdout)
        ' | python3 - "${!env[@]}" "${env[@]}"
    elif [ "$format" == "sh" ]; then
        declare name
        for name in "${!env[@]}"; do
            echo "export $name=${env[$name]@Q}"
        done
    else
        echo "Unknown environment output format: ${format@Q}" >&2
        exit 1
    fi
}

# Deploy Cloud Functions
# Args: --sections=GLOB
#       --project=NAME --prefix=PREFIX --source=PATH
#       --load-queue-trigger-topic=NAME
#       --pick-notifications-trigger-topic=NAME
#       --updated-urls-topic=NAME
#       --updated-topic=NAME
#       --spool-collection-path=PATH
#       --cache-redirect-function-name=NAME
#       --env-yaml=YAML
function cloud_functions_deploy() {
    declare params
    params="$(getopt_vars sections project prefix source \
                          load_queue_trigger_topic \
                          pick_notifications_trigger_topic \
                          updated_urls_topic \
                          updated_topic \
                          spool_collection_path \
                          cache_redirect_function_name \
                          env_yaml \
                          -- "$@")"
    eval "$params"
    # Create empty environment YAML
    declare env_yaml_file
    env_yaml_file=`mktemp --tmpdir kcidb_cloud_env.XXXXXXXX`
    # Store environment YAML
    echo -n "$env_yaml" >| "$env_yaml_file"

    # Deploy functions back-to-front pipeline-wise,
    # so compatibility is preserved in the process
    declare trigger_event="providers/cloud.firestore/eventTypes/"
    trigger_event+="document.create"
    declare trigger_resource="projects/$project/databases/(default)/documents/"
    trigger_resource+="${spool_collection_path}/{notification_id}"
    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          pick_notifications \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-topic "${pick_notifications_trigger_topic}" \
                          --memory 256MB \
                          --max-instances=1 \
                          --timeout 540

    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          send_notification \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-event "${trigger_event}" \
                          --trigger-resource "${trigger_resource}" \
                          --memory 256MB \
                          --retry \
                          --max-instances=1 \
                          --timeout 540

    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          spool_notifications \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-topic "${updated_topic}" \
                          --memory 2048MB \
                          --max-instances=10 \
                          --timeout 540

    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          "$cache_redirect_function_name" \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-http \
                          --allow-unauthenticated \
                          --memory 256MB \
                          --max-instances=16 \
                          --timeout 30

    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          cache_urls \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-topic "${updated_urls_topic}" \
                          --memory 256MB \
                          --max-instances=1 \
                          --timeout 540

    cloud_function_deploy "$sections" "$source" "$project" "$prefix" \
                          load_queue \
                          --env-vars-file "$env_yaml_file" \
                          --trigger-topic "${load_queue_trigger_topic}" \
                          --memory 1024MB \
                          --max-instances=1 \
                          --timeout 540
    # Remove the environment YAML file
    rm "$env_yaml_file"
}

# Withdraw Cloud Functions
# Args: --sections=GLOB --project=NAME --prefix=PREFIX
#       --cache-redirect-function-name=NAME
function cloud_functions_withdraw() {
    declare params
    params="$(getopt_vars sections project prefix \
                          cache_redirect_function_name \
                          -- "$@")"
    eval "$params"
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            pick_notifications
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            send_notification
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            spool_notifications
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            "$cache_redirect_function_name"
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            cache_urls
    cloud_function_withdraw "$sections" "$project" "$prefix" \
                            load_queue
}

# Check if a scheduler job exists
# Args: project name
# Output: "true" if the subscription exists, "false" otherwise.
function scheduler_job_exists() {
    declare -r project="$1"; shift
    declare -r name="$1"; shift
    declare output
    if output=$(
            gcloud scheduler jobs describe --quiet --project="$project" \
                                           "$name" 2>&1
       ); then
        echo "true"
    elif [[ $output == *NOT_FOUND* ]]; then
        echo "false"
    else
        echo "$output" >&2
        false
    fi
}

# Deploy a pubsub scheduler job
# Args: project name topic schedule message_body
function scheduler_job_pubsub_deploy() {
    declare -r project="$1"; shift
    declare -r name="$1"; shift
    declare -r topic="$1"; shift
    declare -r schedule="$1"; shift
    declare -r message_body="$1"; shift
    declare -r -a args=(
        "${name}"
        --quiet
        --project="$project"
        --topic="$topic"
        --schedule="$schedule"
        --message-body="$message_body"
    )
    exists=$(scheduler_job_exists "$project" "$name")
    if "$exists"; then
        mute gcloud scheduler jobs update pubsub "${args[@]}"
    else
        mute gcloud scheduler jobs create pubsub "${args[@]}"
    fi
}

# Delete a scheduler job if it exists
# Args: project name
function scheduler_job_withdraw() {
    declare -r project="$1"; shift
    declare -r name="$1"; shift
    exists=$(scheduler_job_exists "$project" "$name")
    if "$exists"; then
        mute gcloud scheduler jobs delete \
            --quiet --project="$project" "$name"
    fi
}

# Deploy to scheduler
# Args: --project=NAME
#       --prefix=STRING
#       --load-queue-trigger-topic=NAME
#       --pick-notifications-trigger-topic=NAME
function scheduler_deploy() {
    declare params
    params="$(getopt_vars project \
                          prefix \
                          load_queue_trigger_topic \
                          pick_notifications_trigger_topic \
                          -- "$@")"
    eval "$params"
    # Deploy the jobs
    scheduler_job_pubsub_deploy "$project" "${prefix}load_queue_trigger" \
                                "$load_queue_trigger_topic" '* * * * *' '{}'
    scheduler_job_pubsub_deploy "$project" "${prefix}pick_notifications_trigger" \
                                "$pick_notifications_trigger_topic" \
                                 '*/10 * * * *' '{}'
}

# Withdraw from the scheduler
# Args: project prefix
function scheduler_withdraw() {
    declare -r project="$1"; shift
    declare -r prefix="$1"; shift
    scheduler_job_withdraw "$project" "${prefix}load_queue_trigger"
    scheduler_job_withdraw "$project" "${prefix}pick_notifications_trigger"
}

# Deploy permissions for a submitter
# Args: project new_topic submitter
function submitter_deploy() {
    declare -r project="$1"; shift
    declare -r new_topic="$1"; shift
    declare -r submitter="$1"; shift
    declare member
    declare role

    member="serviceAccount:$submitter@$project.iam.gserviceaccount.com"

    role="roles/pubsub.publisher"
    mute gcloud pubsub topics add-iam-policy-binding --project="$project" \
                                                     "$new_topic" \
                                                     --quiet \
                                                     --member="$member" \
                                                     --role="$role"
}

# Remove permissions for a submitter
# Args: project new_topic submitter
function submitter_withdraw() {
    declare -r project="$1"; shift
    declare -r new_topic="$1"; shift
    declare -r submitter="$1"; shift
    declare member
    member="serviceAccount:$submitter@$project.iam.gserviceaccount.com"

    iam_policy_binding_withdraw "$project" "$member" \
                                "roles/bigquery.dataViewer"
    iam_policy_binding_withdraw "$project" "$member" \
                                "roles/bigquery.jobUser"
    pubsub_topic_iam_policy_binding_withdraw "$project" "$new_topic" \
                                             "$member" \
                                             "roles/pubsub.publisher"
}

# Deploy submitter permissions
# Args: project new_topic [submitter...]
function submitters_deploy() {
    declare -r project="$1"; shift
    declare -r new_topic="$1"; shift
    declare -r -a submitters=("$@")
    for submitter in "${submitters[@]}"; do
        submitter_deploy "$project" "$new_topic" "$submitter"
    done
}

# Withdraw submitter permissions
# Args: project new_topic [submitter...]
function submitters_withdraw() {
    declare -r project="$1"; shift
    declare -r new_topic="$1"; shift
    declare -r -a submitters=("$@")
    for submitter in "${submitters[@]}"; do
        submitter_withdraw "$project" "$new_topic" "$submitter"
    done
}

# Sections of the installation
declare -A -r SECTIONS=(
    ["bigquery"]="BigQuery dataset"
    ["psql"]="PostgreSQL database"
    ["pubsub"]="Pub/Sub topics and subscriptions"
    ["secrets"]="Secrets"
    ["firestore"]="Firestore database"
    ["storage"]="Google cloud storage"
    ["cloud_functions.pick_notifications"]="Cloud Functions: kcidb_pick_notifications()"
    ["cloud_functions.send_notification"]="Cloud Functions: kcidb_send_notification()"
    ["cloud_functions.spool_notifications"]="Cloud Functions: kcidb_spool_notifications()"
    ["cloud_functions.cache_redirect"]="Cloud Functions: kcidb_cache_redirect()"
    ["cloud_functions.cache_urls"]="Cloud Functions: kcidb_cache_urls()"
    ["cloud_functions.load_queue"]="Cloud Functions: kcidb_load_queue()"
    ["scheduler"]="Scheduler jobs"
    ["submitters"]="Submitter permissions"
)
# Maximum length of a section name
declare SECTIONS_NAME_LEN_MAX=0
# Maximum length of a section description
declare SECTIONS_DESCRIPTION_LEN_MAX=0
# Calculate maximum lengths
declare SECTIONS_NAME
for SECTIONS_NAME in "${!SECTIONS[@]}"; do
    if ((${#SECTIONS_NAME} > SECTIONS_NAME_LEN_MAX)); then
        SECTIONS_NAME_LEN_MAX="${#SECTIONS_NAME}"
    fi
    if ((${#SECTIONS[$SECTIONS_NAME]} > SECTIONS_DESCRIPTION_LEN_MAX)); then
        SECTIONS_DESCRIPTION_LEN_MAX="${#SECTIONS[$SECTIONS_NAME]}"
    fi
done
unset SECTIONS_NAME
declare -r SECTIONS_NAME_LEN_MAX
declare -r SECTIONS_DESCRIPTION_LEN_MAX

# Execute an operation on a section of installation, if its name matches a
# glob. The section name is passed as an explicit argument. The operation is
# also passed explicitly as the operation verb, and the corresponding command
# to execute.
#
# Args: glob name verb command [arg...]
function sections_run_explicit() {
    declare -r glob="$1"; shift
    declare -r name="$1"; shift
    declare -r verb="$1"; shift
    declare -r command="$1"; shift
    declare -r action="${verb}ing"

    if ! [[ -v SECTIONS[$name] ]]; then
        echo "Unknown section name ${name@Q}" >&2
        exit 1
    fi

    if [[ $name != $glob ]]; then
        return
    fi

    verbose printf "%s %-${SECTIONS_DESCRIPTION_LEN_MAX}s [%s]\\n" \
                   "${action^}" "${SECTIONS[$name]}" "$name"
    aterr_push "echo Failed ${action@Q} ${SECTIONS[$name]@Q} '['${name@Q}']'"
    "${command}" "$@"
    aterr_pop
}

# Execute an operation on a section of installation, if its name matches a
# glob. The operation is defined as a command with arguments. The command name
# must consist of the (multi-word) section name and the single-word operation
# verb, with all words separated by underscores.
#
# Args: glob command [arg...]
function sections_run() {
    declare -r glob="$1"; shift
    declare -r command="$1"; shift
    declare -r name="${command%_*}"
    declare -r verb="${command##*_}"

    if [ -z "$name" ]; then
        echo "No section name found in command name ${command@Q}" >&2
        exit 1
    fi
    if [ -z "$verb" ]; then
        echo "No operation verb found in command name ${command@Q}" >&2
        exit 1
    fi

    sections_run_explicit "$glob" "$name" "$verb" "$command" "$@"
}

# Execute a deploy/withdraw command
# Args: --command=NAME
#       --format=yaml|sh
#       --sections=EXTGLOB
#       --project=NAME
#       --prefix=STRING
#       --version=STRING
#       --extra-cc=ADDRS
#       --smtp-to-addrs=STRING
#       --smtp-mocked=true|false
#       --test=true|false
#       --log-level=NAME
#       --optimize=PYTHONOPTIMIZE
#       --heavy-asserts=true|false
#       --updated-publish=true|false
#       --submitters=WORDS
#       --argv=WORDS
function execute_command() {
    declare params
    params="$(getopt_vars command \
                          format \
                          project \
                          sections \
                          prefix \
                          version \
                          extra_cc \
                          smtp_to_addrs \
                          smtp_mocked \
                          test \
                          log_level \
                          optimize \
                          heavy_asserts \
                          updated_publish \
                          submitters \
                          argv \
                          -- "$@")"
    eval "$params"
    # Convert submitters and extra args from a string of words to an array
    eval "declare -a submitters=($submitters)"
    eval "declare -a argv=($argv)"

    declare -r load_queue_trigger_topic="${prefix}load_queue_trigger"
    declare -r cache_bucket_name="${project}_${prefix}cache"
    declare -r pick_notifications_trigger_topic="${prefix}pick_notifications_trigger"
    declare -r cache_redirect_function_name="cache_redirect"
    declare cache_redirector_url="https://${CLOUD_FUNCTION_REGION}"
    declare cache_redirector_url+="-${project}.cloudfunctions.net/"
    declare cache_redirector_url+="${prefix}"
    declare -r cache_redirector_url+="${cache_redirect_function_name}"
    declare -r updated_urls_topic="${prefix}updated_urls"
    declare -r new_topic="${prefix}new"
    declare -r new_load_subscription="${prefix}new_load"
    declare -r new_debug_subscription="${prefix}new_debug"
    declare -r updated_topic="${prefix}updated"
    declare -r updated_debug_subscription="${prefix}updated_debug"
    declare -r spool_collection_path="${prefix}notifications"
    declare -r smtp_password_secret="kcidb_smtp_password"

    declare -r psql_connection=$(
        echo -n "${project}:"
        echo -n "${PSQL_INSTANCE_REGION}:"
        echo -n "${PSQL_INSTANCE}"
    )
    declare -r psql_socket_dir="/cloudsql/${psql_connection}"
    declare -r psql_database="${prefix}${version}"
    declare -r psql_clean_test_database="${prefix}${version}_clean_test"
    declare -r psql_empty_test_database="${prefix}${version}_empty_test"
    declare -r psql_submitter="${psql_database}_submitter"
    declare -r psql_pgpass_secret="${prefix}psql_pgpass"
    declare -r psql_kcidb_db=$(
        echo -n "postgresql: "
        # Use the local proxy for the shell
        if [ "$command" != "shell" ]; then
            echo -n "host=${psql_socket_dir}" | escape_whitespace
            echo -n " "
            echo -n "user=${psql_submitter}"
            echo -n " "
        fi
        echo -n "dbname=${psql_database}" | escape_whitespace
    )
    declare -r psql_clean_test_kcidb_db=$(
        echo -n "postgresql:"
        echo -n "dbname=${psql_clean_test_database}" | escape_whitespace
    )
    declare -r psql_empty_test_kcidb_db=$(
        echo -n "postgresql:"
        echo -n "dbname=${psql_empty_test_database}" | escape_whitespace
    )
    declare -a psql_args=("$project" "$psql_database" "$psql_submitter")
    if "$test"; then
        psql_args+=(
            # Do not initialize the clean database
            "#$psql_clean_test_database"
            "${psql_clean_test_database}_submitter"
            "$psql_empty_test_database"
            "${psql_empty_test_database}_submitter"
        )
    fi
    declare -a -r psql_args

    # Enable fetching PostgreSQL passwords from their secrets
    password_set_secret "psql_superuser" "$project" "kcidb_psql_superuser"
    password_set_secret "psql_viewer" "$project" "kcidb_psql_viewer"
    password_set_secret "psql_submitter" "$project" "${prefix}psql_submitter"

    declare -r bigquery_dataset="${prefix}${version}"
    declare -r bigquery_clean_test_dataset="${prefix}${version}_clean_test"
    declare -r bigquery_empty_test_dataset="${prefix}${version}_empty_test"
    declare -r bigquery_kcidb_db="bigquery:${project}.${bigquery_dataset}"
    declare bigquery_clean_test_kcidb_db="bigquery:${project}."
    declare -r bigquery_clean_test_kcidb_db+="${bigquery_clean_test_dataset}"
    declare bigquery_empty_test_kcidb_db="bigquery:${project}."
    declare -r bigquery_empty_test_kcidb_db+="${bigquery_empty_test_dataset}"
    declare -a bigquery_args=("$project" "$bigquery_dataset")
    if "$test"; then
        bigquery_args+=(
            # Do not initialize the clean dataset
            "#$bigquery_clean_test_dataset"
            "$bigquery_empty_test_dataset"
        )
    fi
    declare -a -r bigquery_args

    declare -r database=$(
        echo -n "mux: "
        echo -n "$psql_kcidb_db" | escape_whitespace
        echo -n " "
        echo -n "$bigquery_kcidb_db" | escape_whitespace
    )

    if "$test"; then
        declare -r sqlite_clean_test_file="$TMPDIR/clean.sqlite3"
        touch "$sqlite_clean_test_file"
        declare clean_test_databases=$(
            echo -n "sqlite:$sqlite_clean_test_file" | escape_whitespace
            echo -n " "
            echo -n "$psql_clean_test_kcidb_db" | escape_whitespace
            echo -n " "
            echo -n "$bigquery_clean_test_kcidb_db" | escape_whitespace
        )
        declare -r clean_test_databases=$(
            echo -n "$clean_test_databases"
            echo -n " "
            echo -n "mux:$clean_test_databases" | escape_whitespace
        )
    else
        declare -r clean_test_databases=""
    fi

    if "$test"; then
        declare -r sqlite_empty_test_kcidb_db="sqlite:$TMPDIR/empty.sqlite3"
        mute kcidb-db-init -lDEBUG -d "$sqlite_empty_test_kcidb_db"
        declare empty_test_databases=$(
            echo -n "$sqlite_empty_test_kcidb_db" | escape_whitespace
            echo -n " "
            echo -n "$psql_empty_test_kcidb_db" | escape_whitespace
            echo -n " "
            echo -n "$bigquery_empty_test_kcidb_db" | escape_whitespace
        )
        declare -r empty_test_databases=$(
            echo -n "$empty_test_databases"
            echo -n " "
            echo -n "mux:$empty_test_databases" | escape_whitespace
        )
    else
        declare -r empty_test_databases=""
    fi

    # Register SMTP password secret
    password_set_secret "smtp" "$project" "$SMTP_PASSWORD_SECRET"

    declare -r smtp_topic=$("$smtp_mocked" && echo "${prefix}smtp" || true)
    declare -r smtp_subscription=$(
        "$smtp_mocked" && echo "${prefix}smtp_received" || true
    )

    declare -r -a env_args=(
        --project="$project"
        --log-level="$log_level"
        --cache-bucket-name="$cache_bucket_name"
        --cache-redirector-url="$cache_redirector_url"
        --optimize="$optimize"
        --heavy-asserts="$heavy_asserts"
        --new-topic="$new_topic"
        --new-load-subscription="$new_load_subscription"
        --updated-publish="$updated_publish"
        --updated-topic="$updated_topic"
        --updated-urls-topic="$updated_urls_topic"
        --spool-collection-path="$spool_collection_path"
        --extra-cc="$extra_cc"
        --smtp-to-addrs="$smtp_to_addrs"
        --smtp-password-secret="$SMTP_PASSWORD_SECRET"
        --smtp-topic="$smtp_topic"
        --smtp-subscription="$smtp_subscription"
        --pgpass-secret="$psql_pgpass_secret"
        --database="$database"
        --clean-test-databases="$clean_test_databases"
        --empty-test-databases="$empty_test_databases"
    )

    # Handle "env" command, if specified
    if [ "$command" == "env" ]; then
        cloud_functions_env --format="$format" "${env_args[@]}"
        return
    fi

    declare -r -a env_yaml=$(
        cloud_functions_env --format=yaml "${env_args[@]}"
    )

    # Make sure requisite services are enabled
    app_deploy "$project"
    services_enable "$project" appengine secretmanager cloudfunctions \
                               cloudbuild cloudscheduler firestore \
                               sqladmin storage

    # Enable generating PostgreSQL superuser password (if not specified),
    # if the instance doesn't exist yet
    declare exists
    exists=$(psql_instance_exists "$project" "$PSQL_INSTANCE")
    if ! "$exists"; then
        password_set_generate psql_superuser true
    fi

    if [ "$command" == "deploy" ]; then
        sections_run "$sections" secrets_deploy "$project" \
            "$psql_pgpass_secret" "$psql_submitter"
        sections_run "$sections" bigquery_deploy "${bigquery_args[@]}"
        sections_run "$sections" psql_deploy "${psql_args[@]}"
        sections_run "$sections" pubsub_deploy \
            --project="$project" \
            --load-queue-trigger-topic="$load_queue_trigger_topic" \
            --new-topic="$new_topic" \
            --new-load-subscription="$new_load_subscription" \
            --new-debug-subscription="$new_debug_subscription" \
            --updated-topic="$updated_topic" \
            --updated-urls-topic="$updated_urls_topic" \
            --updated-debug-subscription="$updated_debug_subscription" \
            --pick-notifications-trigger-topic \
              "$pick_notifications_trigger_topic" \
            --smtp-topic="$smtp_topic" \
            --smtp-subscription="$smtp_subscription"
        sections_run "$sections" firestore_deploy "$project"
        sections_run "$sections" storage_deploy "$project" "$cache_bucket_name"
        cloud_functions_deploy \
            --sections="$sections" \
            --project="$project" \
            --prefix="$prefix" \
            --source="$(dirname "$(realpath "$0")")" \
            --load-queue-trigger-topic="$load_queue_trigger_topic" \
            --pick-notifications-trigger-topic \
              "$pick_notifications_trigger_topic" \
            --updated-urls-topic="$updated_urls_topic" \
            --updated-topic="$updated_topic" \
            --cache-redirect-function-name="$cache_redirect_function_name" \
            --spool-collection-path="$spool_collection_path" \
            --env-yaml="${env_yaml}"
        sections_run "$sections" scheduler_deploy \
            --project="$project" \
            --prefix="$prefix" \
            --load-queue-trigger-topic="$load_queue_trigger_topic" \
            --pick-notifications-trigger-topic="$pick_notifications_trigger_topic"
        sections_run "$sections" submitters_deploy \
            "$project" "$new_topic" "${submitters[@]}"
    elif [ "$command" == "shell" ]; then
        export GCP_PROJECT="$project"
        source <(cloud_functions_env --format=sh "${env_args[@]}")
        export KCIDB_DEPLOYMENT="${KCIDB_DEPLOYMENT:-1}"
        if (( ${#argv[@]} )); then
            argv=("$SHELL" "-c" "${argv[*]@Q}")
        else
            argv=("$SHELL" "-i")
        fi
        psql_proxy_session "$project" "$PSQL_INSTANCE" "${argv[@]}"
    elif [ "$command" == "withdraw" ]; then
        sections_run "$sections" submitters_withdraw \
            "$project" "$new_topic" "${submitters[@]}"
        sections_run "$sections" scheduler_withdraw "$project" "$prefix"
        cloud_functions_withdraw \
            --sections="$sections" \
            --project="$project" \
            --prefix="$prefix" \
            --cache-redirect-function-name="$cache_redirect_function_name"
        sections_run "$sections" storage_withdraw "$cache_bucket_name"
        sections_run "$sections" firestore_withdraw \
            "$project" "$spool_collection_path"
        sections_run "$sections" pubsub_withdraw \
            --project="$project" \
            --load-queue-trigger-topic="$load_queue_trigger_topic" \
            --pick-notifications-trigger-topic \
              "$pick_notifications_trigger_topic" \
            --new-topic="$new_topic" \
            --new-load-subscription="$new_load_subscription" \
            --new-debug-subscription="$new_debug_subscription" \
            --updated-urls-topic="$updated_urls_topic" \
            --updated-topic="$updated_topic" \
            --updated-debug-subscription="$updated_debug_subscription" \
            --smtp-topic="$smtp_topic" \
            --smtp-subscription="$smtp_subscription"
        sections_run "$sections" psql_withdraw "${psql_args[@]}"
        sections_run "$sections" bigquery_withdraw "${bigquery_args[@]}"
        sections_run "$sections" secrets_withdraw "$project" \
            "$psql_pgpass_secret"
    fi
}

# Output usage information
function usage() {
    echo "Usage: $(basename "$0") [OPTION...] COMMAND [COMMAND_ARGUMENT...]"
    echo "Manage KCIDB installation in a Google Cloud project."
    echo ""
    echo "Commands:"
    echo ""
    echo "    deploy        Deploy an installation to the cloud."
    echo "    env           Output environment YAML for Cloud Functions."
    echo "    shell         Execute a shell with deployment environment."
    echo "    withdraw      Withdraw an installation from the cloud."
    echo "    list-sections List sections of the installation."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo "              To get command usage message run "
    echo "              $(basename "$0") COMMAND -h/--help."
    echo ""
}

# Output deploy command usage information
function usage_deploy() {
    echo "Usage: $(basename "$0") deploy [OPTION...]" \
         "PROJECT NAMESPACE [VERSION]"
    echo "Deploy a KCIDB installation to a Google Cloud project."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo "    -v, --verbose"
    echo "              Output the deployment steps being executed."
    echo "    -s, --sections=EXTGLOB"
    echo "              Specify an extended shell glob matching the"
    echo "              installation sections to limit deployment to."
    echo "              See output of \"$(basename "$0") list-sections\""
    echo "              for a list of available sections."
    echo "    --extra-cc=ADDRS"
    echo "              Add specified addresses to CC of all emails."
    echo "    --smtp-to-addrs=ADDRS"
    echo "              Specify a comma-separated list of addresses"
    echo "              to override recipients of email notifications."
    echo "    --smtp-password-file=FILE"
    echo "              Specify a file with the SMTP server password,"
    echo "              or \"-\" to read it from stdin."
    echo "    --smtp-mocked"
    echo "              Post notification messages to a PubSub topic,"
    echo "              instead of sending them to the SMTP server."
    echo "              Used when testing deployments."
    echo "    --psql-password-file=FILE"
    echo "              Specify a file with the password for the PostgreSQL"
    echo "              superuser, or \"-\" to read it from stdin."
    echo "    --log-level=NAME"
    echo "              Specify Python log level NAME for Cloud Functions."
    echo "              Default is INFO."
    echo "    --optimize=PYTHONOPTIMIZE"
    echo "              Specify a value for PYTHONOPTIMIZE to be added to the environment"
    echo "              Default is an empty string."
    echo "    --heavy-asserts"
    echo "              Enable heavy assertion checking in deployment."
    echo "    --mute-updates"
    echo "              Disable posting updates about loaded data."
    echo "    --test"
    echo "              Deploy test resources in various sections."
    echo "    --submitter=NAME"
    echo "              Specify a service account to permit submissions for."
    echo "              Repeat to add more submitters."
    echo ""
    echo "Positional arguments:"
    echo ""
    echo "    PROJECT   Google Cloud project ID, e.g. \"kernelci-production\"."
    echo "    NAMESPACE Namespace for all objects, e.g. \"test\"."
    echo "    VERSION   Optional version of the dataset, e.g. 4."
    echo ""
}

# Output env command usage information
function usage_env() {
    echo "Usage: $(basename "$0") env [OPTION...]" \
         "PROJECT NAMESPACE [VERSION]"
    echo "Output environment YAML used by KCIDB Cloud Functions."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo "    --format=FORMAT"
    echo "              Specify either \"yaml\" or \"sh\" as the output"
    echo "              format. Default is \"yaml\"."
    echo "    --extra-cc=ADDRS"
    echo "              Add specified addresses to CC of all emails."
    echo "    --smtp-to-addrs=ADDRS"
    echo "              Specify a comma-separated list of addresses"
    echo "              to override recipients of email notifications."
    echo "    --smtp-mocked"
    echo "              Post notification messages to a PubSub topic,"
    echo "              instead of sending them to the SMTP server."
    echo "              Used when testing deployments."
    echo "    --log-level=NAME"
    echo "              Specify Python log level NAME for Cloud Functions."
    echo "              Default is INFO."
    echo "    --optimize=PYTHONOPTIMIZE"
    echo "              Specify a value for PYTHONOPTIMIZE to be added to the environment"
    echo "              Default is an empty string."
    echo "    --heavy-asserts"
    echo "              Enable heavy assertion checking in deployment."
    echo "    --mute-updates"
    echo "              Disable posting updates about loaded data."
    echo "    --test"
    echo "              Enable various test resources."
    echo ""
    echo "Positional arguments:"
    echo ""
    echo "    PROJECT   Google Cloud project ID, e.g. \"kernelci-production\"."
    echo "    NAMESPACE Namespace for all objects, e.g. \"test\"."
    echo "    VERSION   Optional version of the dataset, e.g. 4."
    echo ""
}

# Output shell command usage information
function usage_shell() {
    echo "Usage: $(basename "$0") shell [OPTION...]" \
         "PROJECT NAMESPACE [VERSION [CMD [ARG...]]"
    echo "Execute a shell with deployment environment."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo "    --extra-cc=ADDRS"
    echo "              Add specified addresses to CC of all emails."
    echo "    --smtp-to-addrs=ADDRS"
    echo "              Specify a comma-separated list of addresses"
    echo "              to override recipients of email notifications."
    echo "    --smtp-mocked"
    echo "              Expect notification messages to be posted to a"
    echo "              PubSub topic, instead of being sent to the SMTP"
    echo "              server."
    echo "    --log-level=NAME"
    echo "              Specify Python log level NAME for Cloud Functions."
    echo "              Default is INFO."
    echo "    --optimize=PYTHONOPTIMIZE"
    echo "              Specify a value for PYTHONOPTIMIZE to be added to the environment"
    echo "              Default is an empty string."
    echo "    --heavy-asserts"
    echo "              Enable heavy assertion checking in deployment."
    echo "    --mute-updates"
    echo "              Expect updates about loaded data to be disabled."
    echo "    --test"
    echo "              Expect various test resources to be deployed."
    echo ""
    echo "Positional arguments:"
    echo ""
    echo "    PROJECT   Google Cloud project ID, e.g. \"kernelci-production\"."
    echo "    NAMESPACE Namespace for all objects, e.g. \"test\"."
    echo "    VERSION   Optional version of the dataset, e.g. 4."
    echo "    CMD       The command to execute inside the shell."
    echo "              If not specified, an interactive shell is started."
    echo "    ARG       An argument to pass to the command, if specified."
    echo ""
}

# Output withdraw command usage information
function usage_withdraw() {
    echo "Usage: $(basename "$0") withdraw [OPTION...]" \
         "PROJECT NAMESPACE [VERSION]"
    echo "Withdraw a KCIDB installation from a Google Cloud project."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo "    -v, --verbose"
    echo "              Output the withdrawal steps being executed."
    echo "    -s, --sections=EXTGLOB"
    echo "              Specify an extended shell glob matching the"
    echo "              installation sections to limit withdrawal to."
    echo "              See output of \"$(basename "$0") list-sections\""
    echo "              for a list of available sections."
    echo "    --smtp-mocked"
    echo "              Withdraw the PubSub topic receiving notification"
    echo "              messages instead of the SMTP server"
    echo "              Used when testing deployments."
    echo "    --test"
    echo "              Withdraw test resources from various sections."
    echo "    --submitter=NAME"
    echo "              Specify a service account to deny submissions for."
    echo "              Repeat to add more submitters."
    echo ""
    echo "Positional arguments:"
    echo ""
    echo "    PROJECT   Google Cloud project ID, e.g. \"kernelci-production\"."
    echo "    NAMESPACE Namespace for all objects, e.g. \"test\"."
    echo "    VERSION   Optional version of the dataset, e.g. 4."
    echo ""
}

# Output list-sections command usage information
function usage_list_sections() {
    echo "Usage: $(basename "$0") list-sections [OPTION...] [EXTGLOB]"
    echo "List sections of a KCIDB installation."
    echo ""
    echo "Options:"
    echo ""
    echo "    -h, --help"
    echo "              Display this usage message and exit."
    echo ""
    echo "Positional arguments:"
    echo ""
    echo "    EXTGLOB   Extended shell glob matching the installation"
    echo "              sections to list. Default is \"*\"."
    echo ""
}

# Execute
# Args: [argument...]
function execute() {
    declare args_expr

    # Make sure getopt compatibility isn't enforced
    unset GETOPT_COMPATIBLE
    # Check if getopt is enhanced and supports quoting
    if getopt --test >/dev/null; [ $? != 4 ]; then
        echo "Enhanced getopt not found" >&2
        exit 1
    fi

    # Parse global command-line arguments
    args_expr=$(getopt --name $(basename "$0") \
                       --options "+h" --longoptions "help" \
                       -- "$@")
    eval set -- "$args_expr"
    while true; do
        case "$1" in
            -h|--help) usage; exit 0;;
            --) shift; break;;
            *) echo "Unknown option: $1" >&2; exit 1;;
        esac
    done
    if (( $# < 1 )); then
        echo "Command is not specified" >&2
        usage >&2
        exit 1
    fi

    # Parse command and its arguments
    declare -r command="$1"; shift
    declare getopt_shortopts="h"
    declare getopt_longopts="help"

    if [[ $command == @(deploy|env|shell|withdraw) ]]; then
        getopt_longopts+=",smtp-mocked,test"
        if [[ $command == @(deploy|withdraw) ]]; then
            getopt_shortopts+="vs:"
            getopt_longopts+=",verbose,sections:,submitter:"
        fi
        if [[ $command == @(deploy|env|shell) ]]; then
            getopt_longopts+=",extra-cc:,smtp-to-addrs:"
            getopt_longopts+=",log-level:,optimize:,heavy-asserts,mute-updates"
            if [[ $command == env ]]; then
                getopt_longopts+=",format:"
            fi
        fi
        if [[ $command == @(deploy) ]]; then
            getopt_longopts+=",smtp-password-file:"
            getopt_longopts+=",psql-password-file:"
        fi
    elif [ "$command" == "list-sections" ]; then
        :
    else
        echo "Unknown command: ${command@Q}" >&2
        usage >&2
        exit 1
    fi

    # Parse command-line arguments
    args_expr=$(getopt --name $(basename "$0") \
                       --options "$getopt_shortopts" \
                       --longoptions "$getopt_longopts" \
                       -- "$@")
    eval set -- "$args_expr"

    # Read option arguments
    declare sections="*"
    declare extra_cc=""
    declare smtp_to_addrs=""
    declare smtp_mocked="false"
    declare test="false"
    declare log_level="INFO"
    declare optimize=""
    declare heavy_asserts="false"
    declare updated_publish="true"
    declare -a submitters=()
    declare format="yaml"
    while true; do
        case "$1" in
            -h|--help) "usage_${command//-/_}"; exit 0;;
            -v|--verbose) VERBOSE="true"; shift;;
            -s|--sections) sections="$2"; shift 2;;
            --extra-cc) extra_cc="$2"; shift 2;;
            --smtp-to-addrs) smtp_to_addrs="$2"; shift 2;;
            --smtp-password-file) password_set_file smtp "$2"; shift 2;;
            --smtp-mocked) smtp_mocked="true"; shift;;
            --psql-password-file)
                password_set_file psql_superuser "$2"; shift 2;;
            --log-level) log_level="$2"; shift 2;;
            --optimize) optimize="$2"; shift 2;;
            --heavy-asserts) heavy_asserts="true"; shift;;
            --mute-updates) updated_publish="false"; shift;;
            --test) test="true"; shift;;
            --format) format="$2"; shift 2;;
            --submitter) submitters+=("$2"); shift 2;;
            --) shift; break;;
            *) echo "Unknown option: $1" >&2; exit 1;;
        esac
    done

    # Process positional arguments according to the command invoked
    if [ "$command" == "list-sections" ]; then
        if (( $# > 1 )); then
            echo "Invalid number of positional arguments" >&2
            "usage_${command//-/_}" >&2
            exit 1
        fi
        declare glob="${1:-*}"
        declare name
        printf '%s\n' "${!SECTIONS[@]}" | sort |
            while read -r name; do
                if [[ $name == $glob ]]; then
                    printf "%-${SECTIONS_NAME_LEN_MAX}s %s\\n" \
                           "$name" "${SECTIONS[$name]}"
                fi
            done
        exit 0
    elif [ "$command" == "shell" ]; then
        if (( $# < 2 )); then
            echo "Invalid number of positional arguments" >&2
            "usage_${command//-/_}" >&2
            exit 1
        fi
    else
        if (( $# < 2 || $# > 3 )); then
            echo "Invalid number of positional arguments" >&2
            "usage_${command//-/_}" >&2
            exit 1
        fi
    fi

    # Read and normalize positional arguments
    declare -r project="$1"; shift
    declare -r namespace="$1"; shift
    if (( $# )); then
        declare version="$1"; shift
    else
        declare version="0"
    fi
    if [[ $version =~ ^[0-9]+$ ]]; then
        version=$(printf %02u "$version")
    else
        echo "Invalid version: $version" >&2
        usage >&2
        exit 1
    fi
    declare -r version
    declare -r -a argv=("$@")

    # Execute the command
    execute_command --command="$command" \
                    --format="$format" \
                    --sections="$sections" \
                    --project="$project" \
                    --prefix="${namespace:-}${namespace:+_}kcidb_" \
                    --version="$version" \
                    --extra-cc="$extra_cc" \
                    --smtp-to-addrs="$smtp_to_addrs" \
                    --smtp-mocked="$smtp_mocked" \
                    --test="$test" \
                    --log-level="$log_level" \
                    --optimize="$optimize" \
                    --heavy-asserts="$heavy_asserts" \
                    --updated-publish="$updated_publish" \
                    --submitters="${submitters[*]@Q}" \
                    --argv="${argv[*]@Q}"
}

execute "$@"
